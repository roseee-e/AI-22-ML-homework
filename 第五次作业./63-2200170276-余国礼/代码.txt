import numpy as np
import pandas as pd
from collections import Counter
from math import log2

# 创建数据集
data = {
    '年龄': ['青年', '青年', '青年', '青年', '青年', '中年', '中年', '中年', '中年', '中年', '老年', '老年', '老年',
             '老年', '老年'],
    '有工作': ['否', '否', '是', '是', '否', '否', '否', '是', '否', '否', '否', '否', '是', '是', '否'],
    '有房子': ['否', '否', '否', '是', '否', '否', '否', '是', '是', '是', '是', '是', '是', '否', '否'],
    '信用': ['一般', '好', '好', '好', '一般', '一般', '好', '好', '非常好', '非常好', '非常好', '好', '非常好', '好',
             '一般'],
    '类别': ['否', '否', '是', '是', '否', '否', '否', '是', '是', '是', '是', '是', '是', '否', '否']
}

df = pd.DataFrame(data)


# 计算熵
def entropy(labels):
    label_counts = Counter(labels)
    total_count = len(labels)
    return -sum((count / total_count) * log2(count / total_count) for count in label_counts.values())


# 计算信息增益
def info_gain(df, split_attribute, target_attribute='类别'):
    total_entropy = entropy(df[target_attribute])

    values, counts = np.unique(df[split_attribute], return_counts=True)
    weighted_entropy = sum(
        (counts[i] / sum(counts)) * entropy(df[df[split_attribute] == values[i]][target_attribute]) for i in
        range(len(values)))

    return total_entropy - weighted_entropy


# ID3算法
def id3(df, target_attribute='类别', attributes=None, default_class=None):
    if attributes is None:
        attributes = df.columns.drop(target_attribute)

    # 如果数据集中所有目标属性相同，则返回该属性
    if len(np.unique(df[target_attribute])) == 1:
        return np.unique(df[target_attribute])[0]

    # 如果数据集为空，则返回默认类
    elif len(df) == 0:
        return default_class

    # 如果属性为空，则返回目标属性中的最多数
    elif len(attributes) == 0:
        return Counter(df[target_attribute]).most_common(1)[0][0]

    else:
        # 默认分类
        default_class = Counter(df[target_attribute]).most_common(1)[0][0]

        # 选择信息增益最大的属性
        gains = [info_gain(df, attr, target_attribute) for attr in attributes]
        best_attr = attributes[np.argmax(gains)]

        # 创建树结构
        tree = {best_attr: {}}

        # 删掉选中的属性
        attributes = [attr for attr in attributes if attr != best_attr]

        for value in np.unique(df[best_attr]):
            sub_data = df[df[best_attr] == value]
            subtree = id3(sub_data, target_attribute, attributes, default_class)
            tree[best_attr][value] = subtree

        return tree


# 构建决策树
decision_tree = id3(df)
print(decision_tree)
