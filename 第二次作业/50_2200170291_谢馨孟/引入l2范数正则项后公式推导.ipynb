{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归模型的损失函数加入L2范数正则项后的形式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J(W) = \\frac{1}{2m} \\sum_{i=1}^{m} (f(x^{(i)}) - y^{(i)})^2 + \\lambda \\|W\\|_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J(W)是损失函数 (W)是模型参数向量 m是样本数量 x^{(i)}是第i个样本的特征向量 y^{(i)}是第i个样本的目标值 f(x^{(i)})是模型的预测值$$\n",
    "λ 是正则化参数，用于控制正则化项的影响。\n",
    "$$\\|W\\|_2^2是参数向量W的L2范数的平方，定义为W^TW$$\n",
    "我们的目标是最小化损失函数J(W),通过梯度下降法来更新模型参数W。\n",
    "首先，我们对损失函数J(W)求偏导数：\n",
    "$$\\frac{\\partial J(W)}{\\partial W} = \\frac{1}{m} X^T (f(X) - Y) + 2\\lambda W$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们使用梯度下降法更新参数W：\n",
    "$$W := W - \\alpha \\frac{\\partial J(W)}{\\partial W}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$其中\\alpha是学习率。$$\n",
    "综合起来，我们得到了带L2范数正则化的梯度下降更新规则：\n",
    "$$W := W - \\alpha \\frac{\\partial J(W)}{\\partial W}$$\n",
    "这个更新规则包括两部分：一部分是基于损失函数关于预测误差的梯度的传统梯度下降更新，另一部分是基于正则项的梯度下降更新，它使得参数向量 W 朝着零向量的方向收缩。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
