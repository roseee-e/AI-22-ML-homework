import numpy as np
import matplotlib.pyplot as plt
from matplotlib import rcParams
import pandas as pd
import matplotlib

config = {
    "mathtext.fontset": 'stix',
    "font.family": 'serif',
    "font.serif": ['SimHei'],
    "font.size": 10,
    'axes.unicode_minus': False
}
rcParams.update(config)

path = r'C:\pycharm\python_learn\regress_data1.csv'
data = pd.read_csv(path)
cols = data.shape[1]
X_data = data.iloc[:,:cols-1]
y_data = data.iloc[:,cols-1:]
data.plot(kind='scatter', x='人口', y='收益', figsize=(4,3))

plt.xlabel('人口')
plt.ylabel('收益')
plt.title('数据分布观测')
plt.tight_layout()
plt.show()


def normalization(X):
    X_min = np.min(X, axis=0)
    X_max = np.max(X, axis=0)
    X_norm = (X - X_min) / (X_max - X_min)
    return X_norm,X_min,X_max

X_data_norm, min_val, max_val = normalization(X_data.values)
# print(X_data_norm)
# print(min_val)
# print(max_val)

X_data_norm = np.insert(X_data_norm, 0, 1, axis=1)
X = X_data_norm
Y = y_data.values
W = np.array([[0.0], [0.0]])

def computeCost(X, Y, W):
    Y_hat = np.dot(X,W)
    loss =np.sum((Y_hat - Y)** 2)/(2*X.shape[0])
    return loss
def gradientDescent(X, Y, W, alpha,lambda_):
    num_train = X.shape[0]
    Y_hat = np.dot(X,W)
    dW = X.T@(Y_hat-Y)/ X.shape[0]
    W =(1-alpha*lambda_/X.shape[0])*W-alpha * dW
    return W
def linearRegression(X,Y, alpha, iters,lambda_):
    loss_his = []
    # step1: initialize the model parameters
    feature_dim = X.shape[1]
    W=np.zeros((feature_dim,1)) ## 初始化W系数矩阵，w 是一个(feature_dim,1)矩阵
    ## repeat step 2 and step 3 untill to the convergence or the end of iterations
    for i in range (iters):
        # step2 : using the initilized parameters to predict the output and calculate the loss
        loss = computeCost(X,Y,W)
        loss_his.append(loss)
        # step3: using the gradient decent method to update the parameters
        W=gradientDescent(X, Y, W, alpha,lambda_)
    return loss_his, W ## 返回损失和模型参数。
def predict(X, W):
    '''
    输入：
        X：测试数据集
        W：模型训练好的参数
    输出：
        y_pre：预测值
    '''
    y_pre = np.dot(X,W)
    return y_pre
# 使用归一化后的数据进行线性回归
alpha = 0.001
lambda_ = 0.5
iters = 30000
loss_his, W = linearRegression(X, Y, alpha, iters, lambda_)

x = np.linspace(0, 1, 100)  # 归一化后的人口数据范围是0到1
f = W[0, 0] + (W[1, 0] * x)
fig, ax = plt.subplots(figsize=(6, 4))
ax.plot(x, f, 'r', label='预测值')
ax.scatter(X[:,1], Y, label='训练数据')  # 注意这里使用归一化后的人口数据
ax.legend(loc=2)
ax.set_xlabel('人口')
ax.set_ylabel('收益', rotation=90)
ax.set_title('预测收益和人口规模')
plt.show()
fig, ax = plt.subplots(figsize=(8, 4))
ax.plot(np.arange(iters), loss_his, 'r')
ax.set_xlabel('迭代次数')
ax.set_ylabel('代价')
ax.set_title('误差和训练Epoch数')
plt.show()

#绘制训练和测试损失曲线

test_data=data.iloc[40:98,:]
X_test = test_data.iloc[:, 0].values.reshape(-1, 1)  # 特征值
Y_test = test_data.iloc[:, 1].values.reshape(-1, 1)  # 目标值

X_test_norm = (X_test - min_val) / (max_val - min_val)
X_test_norm = np.insert(X_test_norm, 0, 1, axis=1)
# 使用训练好的模型W来计算测试损失
test_loss_his = [computeCost(X_test_norm, Y_test, W) for _ in range(iters)]
# 绘制曲线
plt.figure(figsize=(8, 4))
plt.plot(loss_his,'b--', label='Training Loss')
plt.plot(test_loss_his,'r--', label='Test Loss')
plt.xlabel('迭代次数')
plt.ylabel('损失')
plt.title('训练和测试损失曲线')
plt.legend()
plt.show()

#最小二乘法求解线性回归模型
def least_squares(X, Y):
    W = np.linalg.inv(X.T @ X) @ X.T @ Y
    return W
W_least_squares = least_squares(X, Y)
y_pred_train = predict(X, W_least_squares)
plt.figure(figsize=(8, 4))
plt.plot(X[:,1], y_pred_train,'y', label='拟合曲线')
plt.scatter(X[:,1], Y, label='训练数据')
plt.legend()
plt.xlabel('人口')
plt.ylabel('收益', rotation=90)
plt.title('最小二乘法预测回归模型')
plt.show()